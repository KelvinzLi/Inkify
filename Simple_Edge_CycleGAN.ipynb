{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2738,"status":"ok","timestamp":1652456077415,"user":{"displayName":"Kelvin Li","userId":"13315570501262465020"},"user_tz":-60},"id":"sHDo7SPjvzJ1","outputId":"5de9cc8f-74b6-49ec-f030-c4c8b40cd6cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4539,"status":"ok","timestamp":1652456081950,"user":{"displayName":"Kelvin Li","userId":"13315570501262465020"},"user_tz":-60},"id":"9VFc9lpTptCU","outputId":"06b70ef5-2f91-4ac9-b3e1-4280104eebdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.16.1\n"]}],"source":["!pip install -U tensorflow_addons"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3498,"status":"ok","timestamp":1652456085438,"user":{"displayName":"Kelvin Li","userId":"13315570501262465020"},"user_tz":-60},"id":"_CscRDe_wODB","outputId":"2d0c98a9-532a-4fc2-8b9f-f96f4cd795c7","cellView":"form"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.16.1\n"]}],"source":["#@title Import Packages\n","\n","from keras.layers import Conv2D, ReLU, BatchNormalization, Add, Subtract, Concatenate, Input, MaxPooling2D, Layer, InputSpec, Conv2DTranspose, GaussianNoise, GaussianDropout, UpSampling2D, LeakyReLU, AveragePooling2D\n","from keras.optimizers import adam_v2\n","from keras.models import Model, load_model\n","from keras import initializers, regularizers, constraints\n","from keras import backend as K\n","\n","import tensorflow_addons as tfa\n","import tensorflow as tf\n","\n","print(tfa.__version__)\n","\n","from PIL import Image\n","import numpy as np\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A3cUXjSN_h9U","cellView":"form"},"outputs":[],"source":["#@title Instance Normalization Block\n","\n","class InstanceNormalization(Layer):\n","    \"\"\"Instance normalization layer.\n","    Normalize the activations of the previous layer at each step,\n","    i.e. applies a transformation that maintains the mean activation\n","    close to 0 and the activation standard deviation close to 1.\n","    # Arguments\n","        axis: Integer, the axis that should be normalized\n","            (typically the features axis).\n","            For instance, after a `Conv2D` layer with\n","            `data_format=\"channels_first\"`,\n","            set `axis=1` in `InstanceNormalization`.\n","            Setting `axis=None` will normalize all values in each\n","            instance of the batch.\n","            Axis 0 is the batch dimension. `axis` cannot be set to 0 to avoid errors.\n","        epsilon: Small float added to variance to avoid dividing by zero.\n","        center: If True, add offset of `beta` to normalized tensor.\n","            If False, `beta` is ignored.\n","        scale: If True, multiply by `gamma`.\n","            If False, `gamma` is not used.\n","            When the next layer is linear (also e.g. `nn.relu`),\n","            this can be disabled since the scaling\n","            will be done by the next layer.\n","        beta_initializer: Initializer for the beta weight.\n","        gamma_initializer: Initializer for the gamma weight.\n","        beta_regularizer: Optional regularizer for the beta weight.\n","        gamma_regularizer: Optional regularizer for the gamma weight.\n","        beta_constraint: Optional constraint for the beta weight.\n","        gamma_constraint: Optional constraint for the gamma weight.\n","    # Input shape\n","        Arbitrary. Use the keyword argument `input_shape`\n","        (tuple of integers, does not include the samples axis)\n","        when using this layer as the first layer in a Sequential model.\n","    # Output shape\n","        Same shape as input.\n","    # References\n","        - [Layer Normalization](https://arxiv.org/abs/1607.06450)\n","        - [Instance Normalization: The Missing Ingredient for Fast Stylization](\n","        https://arxiv.org/abs/1607.08022)\n","    \"\"\"\n","    def __init__(self,\n","                 axis=None,\n","                 epsilon=1e-3,\n","                 center=True,\n","                 scale=True,\n","                 beta_initializer='zeros',\n","                 gamma_initializer='ones',\n","                 beta_regularizer=None,\n","                 gamma_regularizer=None,\n","                 beta_constraint=None,\n","                 gamma_constraint=None,\n","                 **kwargs):\n","        super(InstanceNormalization, self).__init__(**kwargs)\n","        self.supports_masking = True\n","        self.axis = axis\n","        self.epsilon = epsilon\n","        self.center = center\n","        self.scale = scale\n","        self.beta_initializer = initializers.get(beta_initializer)\n","        self.gamma_initializer = initializers.get(gamma_initializer)\n","        self.beta_regularizer = regularizers.get(beta_regularizer)\n","        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n","        self.beta_constraint = constraints.get(beta_constraint)\n","        self.gamma_constraint = constraints.get(gamma_constraint)\n"," \n","    def build(self, input_shape):\n","        ndim = len(input_shape)\n","        if self.axis == 0:\n","            raise ValueError('Axis cannot be zero')\n"," \n","        if (self.axis is not None) and (ndim == 2):\n","            raise ValueError('Cannot specify axis for rank 1 tensor')\n"," \n","        self.input_spec = InputSpec(ndim=ndim)\n"," \n","        if self.axis is None:\n","            shape = (1,)\n","        else:\n","            shape = (input_shape[self.axis],)\n"," \n","        if self.scale:\n","            self.gamma = self.add_weight(shape=shape,\n","                                         name='gamma',\n","                                         initializer=self.gamma_initializer,\n","                                         regularizer=self.gamma_regularizer,\n","                                         constraint=self.gamma_constraint)\n","        else:\n","            self.gamma = None\n","        if self.center:\n","            self.beta = self.add_weight(shape=shape,\n","                                        name='beta',\n","                                        initializer=self.beta_initializer,\n","                                        regularizer=self.beta_regularizer,\n","                                        constraint=self.beta_constraint)\n","        else:\n","            self.beta = None\n","        self.built = True\n"," \n","    def call(self, inputs, training=None):\n","        input_shape = K.int_shape(inputs)\n","        reduction_axes = list(range(0, len(input_shape)))\n"," \n","        if self.axis is not None:\n","            del reduction_axes[self.axis]\n"," \n","        del reduction_axes[0]\n"," \n","        mean = K.mean(inputs, reduction_axes, keepdims=True)\n","        stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon\n","        normed = (inputs - mean) / stddev\n"," \n","        broadcast_shape = [1] * len(input_shape)\n","        if self.axis is not None:\n","            broadcast_shape[self.axis] = input_shape[self.axis]\n"," \n","        if self.scale:\n","            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n","            normed = normed * broadcast_gamma\n","        if self.center:\n","            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n","            normed = normed + broadcast_beta\n","        return normed\n"," \n","    def get_config(self):\n","        config = {\n","            'axis': self.axis,\n","            'epsilon': self.epsilon,\n","            'center': self.center,\n","            'scale': self.scale,\n","            'beta_initializer': initializers.serialize(self.beta_initializer),\n","            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n","            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n","            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n","            'beta_constraint': constraints.serialize(self.beta_constraint),\n","            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n","        }\n","        base_config = super(InstanceNormalization, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n0n7CPpjAYEb","cellView":"form"},"outputs":[],"source":["#@title Convolution Block\n","\n","def conv_block(x,filter_size,k_size=(3,3), stride=(1,1), lk_alpha=0):\n","  lane=Conv2D(filter_size, k_size, padding='same', strides=stride)(x)\n","  lane=InstanceNormalization(axis=-1)(lane)\n","  lane=LeakyReLU(alpha=lk_alpha)(lane)\n","\n","  return lane"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4cK7rET8nTmu","cellView":"form"},"outputs":[],"source":["#@title Resnet Blocks\n","\n","def rn_block(x,filter_size,k_size=(3,3), down=False, lk_alpha=0):\n","  lane=Conv2D(filter_size, k_size, padding='same')(x)\n","  lane=InstanceNormalization(axis=-1)(lane)\n","  lane=LeakyReLU(alpha=lk_alpha)(lane)\n","  lane=Conv2D(filter_size, k_size, padding='same')(lane)\n","  lane=InstanceNormalization(axis=-1)(lane)\n","\n","  if down:\n","    x=Conv2D(filter_size, (1,1))(x)\n","\n","  lane=Add()([lane,x])\n","\n","  lane=LeakyReLU(alpha=lk_alpha)(lane)\n","\n","  return lane\n","\n","def rn_sequence(lane, round, depth, k_size, lk_alpha):\n","  for i in range(round):\n","    if i==0:\n","      lane=rn_block(lane,depth,k_size,lk_alpha=lk_alpha,down=True)\n","    else:\n","      lane=rn_block(lane,depth,k_size,lk_alpha=lk_alpha)\n","\n","  return lane"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2h--llIvz0Ht","cellView":"form"},"outputs":[],"source":["#@title Resnet-based Patch Discriminator\n","\n","def rn_patch_d(input_shape,opt,k_size,init_k=32,lk_alpha=0,multi_stage=False):\n","  input=Input(shape=input_shape)\n","\n","  lane=rn_block(input,init_k,(3,3), True)\n","\n","  lane=rn_sequence(lane, 2, init_k, k_size, lk_alpha)\n","  lane=MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\")(lane) #128\n","\n","  init_k*=2\n","\n","  lane=rn_sequence(lane, 2, init_k, k_size, lk_alpha)\n","  lane=MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\")(lane) #64\n","\n","  init_k*=2\n","\n","  lane=rn_sequence(lane, 2, init_k, k_size, lk_alpha)\n","  lane=MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\")(lane) #32\n","  \n","  init_k*=2\n","\n","  lane=rn_sequence(lane, 2, init_k, k_size, lk_alpha)\n","  lane=MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\")(lane) #16\n","\n","  init_k*=2\n","\n","  lane=rn_sequence(lane, 2, init_k, k_size, lk_alpha)\n","  lane=MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\")(lane) #8\n","\n","  output=Conv2D(1,(5,5),activation='sigmoid',padding='same')(lane)\n","\n","  net=Model(input,output)\n","  net.compile(loss='binary_crossentropy', optimizer=opt)\n","\n","  return net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zx6-jjGE1A2t","cellView":"form"},"outputs":[],"source":["#@title Regular Patch Discriminator \n","\n","def rg_patch_d(input_shape,opt,k_size,lk_alpha,init_k=32):\n","  input=Input(shape=input_shape)\n","\n","  lane=conv_block(input,init_k,k_size,lk_alpha=lk_alpha)\n","  lane=conv_block(lane,init_k,k_size,lk_alpha=lk_alpha)\n","  lane=MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\")(lane) #128\n","\n","  init_k*=2\n","\n","  lane=conv_block(lane,init_k,k_size,lk_alpha=lk_alpha)\n","  lane=conv_block(lane,init_k,k_size,lk_alpha=lk_alpha)\n","  lane=MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\")(lane) #64\n","\n","  init_k*=2\n","\n","  lane=conv_block(lane,init_k,k_size,lk_alpha=lk_alpha)\n","  lane=conv_block(lane,init_k,k_size,lk_alpha=lk_alpha)\n","  lane=MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\")(lane) #32\n","\n","  init_k*=2\n","\n","  lane=conv_block(lane,init_k,k_size,lk_alpha=lk_alpha)\n","  lane=conv_block(lane,init_k,k_size,lk_alpha=lk_alpha)\n","  lane=MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\")(lane) #16\n","\n","  init_k*=2\n","\n","  lane=conv_block(lane,init_k,k_size,lk_alpha=lk_alpha)\n","  lane=conv_block(lane,init_k,k_size,lk_alpha=lk_alpha)\n","  lane=MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\")(lane) #8\n","  \n","  output=Conv2D(1,(7,7),activation='sigmoid',padding='same')(lane)\n","\n","  net=Model(input,output)\n","  net.compile(loss='binary_crossentropy', optimizer=opt)\n","\n","  return net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPvaim6kj3yj","cellView":"form"},"outputs":[],"source":["#@title Pix2Pix Generator\n","\n","def pp2_generator(input_shape,output_k,lk_alpha=0, k_size=(3,3), depth=32, gdrop=False):\n","  input=Input(input_shape)\n","\n","  lane=conv_block(input,depth,k_size,stride=(2,2), lk_alpha=lk_alpha) #128\n","\n","  if gdrop:\n","    lane=GaussianDropout(0.1)(lane)\n","\n","  depth*=2\n","\n","  lane=conv_block(lane,depth,k_size,stride=(2,2), lk_alpha=lk_alpha) #64\n","\n","  if gdrop:\n","    lane=GaussianDropout(0.1)(lane)\n","\n","  # lane_1=lane\n","  depth*=2\n","\n","  lane=conv_block(lane,depth,k_size,stride=(2,2), lk_alpha=lk_alpha) #32\n","\n","  if gdrop:\n","    lane=GaussianDropout(0.1)(lane)\n","    \n","  # lane_2=lane\n","  depth*=2\n","\n","  lane=rn_sequence(lane, 9, depth, k_size, lk_alpha)\n","\n","  # lane=Concatenate()([lane,lane_2])\n","  depth/=2\n","\n","  lane=Conv2DTranspose(depth,(2,2),strides=(2,2),padding='same')(lane)\n","  # lane=UpSampling2D(size=(2,2), interpolation='nearest')(lane)\n","\n","  # lane=Concatenate()([lane,lane_1])\n","  depth/=2\n","\n","  lane=Conv2DTranspose(depth,(2,2),strides=(2,2),padding='same')(lane)\n","  # lane=UpSampling2D(size=(2,2), interpolation='nearest')(lane)\n","\n","  depth/=2\n","\n","  lane=Conv2DTranspose(depth,(2,2),strides=(2,2),padding='same')(lane)\n","  # lane=UpSampling2D(size=(2,2), interpolation='nearest')(lane)\n","\n","  lane=Conv2D(output_k,(7,7),activation='tanh',padding='same')(lane)\n","\n","  net=Model(input,lane)\n","\n","  return net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsoRBt6-r6wc","cellView":"form"},"outputs":[],"source":["#@title Gaussian Blur Block\n","\n","def gaussian_blur(img, kernel_size=5, sigma=5):\n","    def gauss_kernel(channels, kernel_size, sigma):\n","        ax = tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0)\n","        xx, yy = tf.meshgrid(ax, ax)\n","        kernel = tf.exp(-(xx ** 2 + yy ** 2) / (2.0 * sigma ** 2))\n","        kernel = kernel / tf.reduce_sum(kernel)\n","        kernel = tf.tile(kernel[..., tf.newaxis], [1, 1, channels])\n","        return kernel\n","\n","    gaussian_kernel = gauss_kernel(tf.shape(img)[-1], kernel_size, sigma)\n","    gaussian_kernel = gaussian_kernel[..., tf.newaxis]\n","\n","    return tf.nn.depthwise_conv2d(img, gaussian_kernel, [1, 1, 1, 1],\n","                                  padding='SAME', data_format='NHWC')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gF6T4ZK6hsLI","cellView":"form"},"outputs":[],"source":["#@title Model Composite for Generator Training\n","\n","def Train_g_composite(g_1,g_2,d_1,d_2,image_shape,opt):\n","  \n","  ##g_1: the generator that translate photo from style 1 to style 2\n","  ##g_2: the generator that translate photo from style 2 to style 1\n","  ##d_1: the discriminator that identify photo with style 1 from others\n","  ##d_1: the discriminator that identify photo with style 1 from others\n","\n","  #setting trainability\n","\n","  g_1.trainable=True\n","  g_2.trainable=True\n","\n","  d_1.trainable=False\n","  d_2.trainable=False\n","\n","  ##input_1: input of photo of style 1\n","  ##input_1: input of photo of style 2\n","\n","  input_1=Input(shape=image_shape)\n","  input_2=Input(shape=image_shape)\n","\n","  #image_translated to the alternative style\n","  ##alter_1_2: image transfered from style 1 to style 2\n","  ##alter_1_2: image transfered from style 2 to style 1\n","\n","  alter_1_2=g_1(input_1)\n","  alter_2_1=g_2(input_2)\n","\n","  #translated image traslted back to their original style\n","  ##cycle_1: image that is orinally style 1\n","  ##cycle_2: image that is orinally style 2\n","\n","  cycle_1=g_2(alter_1_2)\n","  cycle_2=g_1(alter_2_1)\n","\n","  #identical translation(expecting no change)\n","  ##idt_1: image with style 1 after identical transformation\n","  ##idt_2: image with style 2 after identical transformation\n","\n","  idt_1=g_2(input_1)\n","  idt_2=g_1(input_2)\n","\n","  #calculate adversial loss\n","  ##ad_1: adversial loss of generator 1\n","  ##ad_2: adversial loss of generator 2\n","\n","  ad_2=d_2(alter_1_2)\n","  ad_1=d_1(alter_2_1)\n","\n","  # net=Model([input_1,input_2], [ad_1, ad_2, cycle_1, cycle_2, idt_1, idt_2])\n","  # net.compile(loss=['binary_crossentropy', 'binary_crossentropy', 'mae', 'mae', 'mae', 'mae'], loss_weights=[5,5,10,10,1,1], optimizer=opt)\n","\n","  net=Model([input_1,input_2], [ad_1, ad_2, cycle_1, cycle_2])\n","  net.compile(loss=['mse', 'mse', 'mae', 'mae'], loss_weights=[1,1,1,1], optimizer=opt)\n","\n","  # net=Model([input_1,input_2], [ad_1, ad_2, minus_1, minus_2])\n","  # net.compile(loss=['mse', 'mse', 'mae', 'mae'], loss_weights=[2,2,10,10], optimizer=opt)\n","\n","  return net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pwEv0Ldna-I","cellView":"form"},"outputs":[],"source":["#@title Model Composite for Discriminator Training\n","\n","def Train_d_composite(g_1,g_2,d_1,d_2,image_shape,opt):\n","  #setting trainability\n","\n","  g_1.trainable=False\n","  g_2.trainable=False\n","\n","  d_1.trainable=True\n","  d_2.trainable=True\n","\n","  #true image input\n","  ##input_1: true image of style 1\n","  ##input_2: true image of style 2\n","\n","  input_1=Input(shape=image_shape)\n","  input_2=Input(shape=image_shape)\n","\n","  #translate true image\n","  ##alter_1_2: translated image from style 1 to 2\n","  ##alter_2_1: translated image from style 2 to 1\n","\n","  alter_1_2=g_1(input_1)\n","  alter_2_1=g_2(input_2)\n","\n","  #evaluate true image\n","\n","  real_1=d_1(input_1)\n","  real_2=d_2(input_2)\n","\n","  #evaluate fake image\n","\n","  fake_1=d_1(alter_2_1)\n","  fake_2=d_2(alter_1_2)\n","\n","  net=Model([input_1,input_2], [real_1, real_2, fake_1, fake_2])\n","  net.compile(loss=['mse', 'mse', 'mse', 'mse'], optimizer=opt, metrics=['accuracy'])\n","  # net.compile(loss=['binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'], optimizer=opt, metrics=['accuracy'])\n","\n","  return net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"In1uaC054kEV","cellView":"form"},"outputs":[],"source":["#@title Image Preprocessing & Preparation\n","\n","def to_binary(image):\n","  image=np.squeeze(image)\n","\n","  for i in range(image.shape[0]):\n","    for ii in range(image.shape[1]):\n","      for iii in range(image.shape[2]):\n","        if image[i][ii][iii]>=0.5:\n","          image[i][ii][iii]=1\n","        else:\n","          image[i][ii][iii]=0\n","\n","  return image\n","\n","def image_encode(x):\n","  return (x-127.5)/127.5\n","\n","def image_decode(x):\n","  return ((x+1)*127.5).astype('uint8')\n","\n","def load_image(num,HED_path,Sobel_path,ratio=0.4,original_path='',gray=False):\n","  img_names=os.listdir(HED_path)\n","  album=[]\n","  index=np.random.randint(len(img_names),size=num)\n","\n","  for ii in index:\n","    img_name=img_names[ii]\n","\n","    HED_img_path=os.path.join(HED_path, img_name)\n","    HED_img=Image.open(HED_img_path)\n","    if gray:\n","      HED_img = HED_img.convert('L') \n","    HED_img=np.array(HED_img)\n","\n","    Sobel_img_path=os.path.join(Sobel_path, img_name)\n","    Sobel_img=Image.open(Sobel_img_path)\n","    if gray:\n","      Sobel_img = Sobel_img.convert('L') \n","    Sobel_img=np.array(Sobel_img)\n","\n","    img=ratio*Sobel_img+(1-ratio)*HED_img\n","    img=np.expand_dims(img,-1)\n","\n","    img=image_encode(img)\n","    album.append(img)\n","  \n","  album=np.array(album)\n","\n","  if original_path!='':\n","    org_album=[]\n","    for ii in index:\n","      img_name=img_names[ii]\n","      img_path=os.path.join(original_path, img_name)\n","      img=Image.open(img_path)\n","      if img.mode!='RGB':\n","        img=img.convert('RGB')\n","      if gray:\n","        img = img.convert('L') \n","      img=np.array(img)\n","      img=image_encode(img)\n","      org_album.append(img)\n","    \n","    org_album=np.array(org_album)\n","\n","    return album, org_album\n","  \n","  else:\n","    return album\n","\n","def specific_load_image(index,HED_path,Sobel_path,ratio=0.4,gray=False):\n","  album=[]\n","\n","  for ii in index:\n","    img_name=str(ii)+'.png'\n","\n","    HED_img_path=os.path.join(HED_path, img_name)\n","    HED_img=Image.open(HED_img_path)\n","    if gray:\n","      HED_img = HED_img.convert('L') \n","    HED_img=np.array(HED_img)\n","\n","    Sobel_img_path=os.path.join(Sobel_path, img_name)\n","    Sobel_img=Image.open(Sobel_img_path)\n","    if gray:\n","      Sobel_img = Sobel_img.convert('L') \n","    Sobel_img=np.array(Sobel_img)\n","\n","    img=ratio*Sobel_img+(1-ratio)*HED_img\n","    img=np.expand_dims(img,-1)\n","\n","    img=image_encode(img)\n","    album.append(img)\n","  \n","  album=np.array(album)\n","\n","  return album\n","\n","def save_image(index,album,path,gray=False):\n","  album=image_decode(album)\n","\n","  save_dir=path+ '/Round_{}'.format(index)\n","\n","  if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","\n","  for ii, photo in enumerate(album):\n","    if gray:\n","      photo=np.squeeze(photo)\n","    img=Image.fromarray(photo.astype('uint8'))\n","    img.save(save_dir+'/{}.png'.format(str(ii)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GSnSBe0u6Ct0","cellView":"form"},"outputs":[],"source":["#@title Output Data Generation\n","\n","def create_zero_patch(num,length):\n","  return np.random.rand(num,length,length,1)/10\n","\n","def create_one_patch(num,length):\n","  return np.ones((num,length,length,1))-np.random.rand(num,length,length,1)/10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDpzjpEg8nPj","cellView":"form"},"outputs":[],"source":["#@title Training\n","\n","def Train_CycleGAN(g_1, g_2, d_1, d_2, load_path_1_HED, load_path_1_Sobel, load_path_2_HED, load_path_2_Sobel, save_path_1, save_path_2, image_shape, gd_ratio=2, pred_index_1=None, pred_index_2=None, save_us=True, reload_multi=32, if_gray=False):\n","  \n","  print('---trace on---')\n","  \n","  img_count=0\n","  base_num=128\n","\n","  opt_1=adam_v2.Adam(learning_rate=2e-4, beta_1=0.5)\n","  opt_2=adam_v2.Adam(learning_rate=1e-4, beta_1=0.5)\n","\n","  g_p=load_model('', custom_objects={\"InstanceNormalization\": InstanceNormalization})\n","\n","  batch_size=4\n","\n","  total_round=4096\n","  save_img_round=8\n","  save_net_round=128\n","  paint_round=16\n","  d_val_round=32\n","\n","  painter_loss_min=100\n","\n","  reload_num=reload_multi*batch_size\n","  reload_ii=-1\n","\n","  train_g=Train_g_composite(g_1,g_2,d_1,d_2,image_shape,opt_1)\n","  train_d=Train_d_composite(g_1,g_2,d_1,d_2,image_shape,opt_2)\n","\n","  patch_size=d_1.output_shape[1]\n","\n","  print('---load images---')\n","\n","  album_g_1=load_image(base_num,load_path_1_HED, load_path_1_Sobel,gray=if_gray)\n","  print('album_g_1 loaded')\n","  album_g_2=load_image(base_num,load_path_2_HED, load_path_2_Sobel,gray=if_gray)\n","  print('album_g_2 loaded')\n","\n","  album_d_1=load_image(base_num,load_path_1_HED, load_path_1_Sobel,gray=if_gray)\n","  print('album_d_1 loaded')\n","  album_d_2=load_image(base_num,load_path_2_HED, load_path_2_Sobel,gray=if_gray)\n","  print('album_d_2 loaded')\n","\n","  pred_album_1=specific_load_image(pred_index_1,load_path_1_HED, load_path_1_Sobel,gray=if_gray)\n","  pred_album_2=specific_load_image(pred_index_2,load_path_2_HED, load_path_2_Sobel,gray=if_gray)\n","\n","  print('---begin training---')\n","\n","  patch_one_d =create_one_patch(batch_size,patch_size)\n","  patch_zero_d=create_zero_patch(batch_size,patch_size)\n","\n","  patch_one_g =np.ones((batch_size,patch_size,patch_size,1))\n","\n","  for ii in range(total_round):\n","    # print(ii)\n","    if ii%reload_multi==0:\n","      new_album_g_1=load_image(reload_num,load_path_1_HED, load_path_1_Sobel,gray=if_gray)\n","      new_album_g_2=load_image(reload_num,load_path_2_HED, load_path_2_Sobel,gray=if_gray)\n","\n","      new_album_d_1=load_image(reload_num,load_path_1_HED, load_path_1_Sobel,gray=if_gray)\n","      new_album_d_2=load_image(reload_num,load_path_2_HED, load_path_2_Sobel,gray=if_gray)\n","\n","      album_g_1=np.concatenate([album_g_1[reload_num:], new_album_g_1], axis=0)\n","      album_g_2=np.concatenate([album_g_2[reload_num:], new_album_g_2], axis=0)\n","\n","      album_d_1=np.concatenate([album_d_1[reload_num:], new_album_d_1], axis=0)\n","      album_d_2=np.concatenate([album_d_2[reload_num:], new_album_d_2], axis=0)\n","\n","      reload_ii+=1\n","    data_g_1=album_g_1[ii*batch_size-reload_ii*reload_num:(ii+1)*batch_size-reload_ii*reload_num]\n","    data_g_2=album_g_2[ii*batch_size-reload_ii*reload_num:(ii+1)*batch_size-reload_ii*reload_num]\n","\n","    data_d_1=album_d_1[ii*batch_size-reload_ii*reload_num:(ii+1)*batch_size-reload_ii*reload_num]\n","    data_d_2=album_d_2[ii*batch_size-reload_ii*reload_num:(ii+1)*batch_size-reload_ii*reload_num]\n","\n","    # feedback_1=train_g.train_on_batch([data_g_1,data_g_2], [patch_one_g, patch_one_g, data_g_1, data_g_2, data_g_1, data_g_2])\n","    feedback_1=train_g.train_on_batch([data_g_1,data_g_2], [patch_one_g, patch_one_g, data_g_1, data_g_2])\n","    # feedback_1=train_g.train_on_batch([data_g_1,data_g_2], [patch_one_g, patch_one_g, minus_zero_g, minus_zero_g])\n","\n","    if ii%gd_ratio==0:  \n","      feedback_2=train_d.train_on_batch([data_d_1,data_d_2], [patch_one_d, patch_one_d, patch_zero_d, patch_zero_d])\n","\n","      print('Round {}: Generator Loss: {} Dircriminator Loss: {}'.format(ii, feedback_1[0], feedback_2[0]))\n","    \n","    else:\n","      print('Round {}: Generator Loss: {}'.format(ii, feedback_1[0]))\n","\n","    if ii%save_img_round==0:\n","      if save_us:\n","        mimic_1=g_2.predict(pred_album_2)\n","        mimic_paint=g_p.predict(mimic_1)\n","        save_image(ii,mimic_paint,save_path_1,if_gray)\n","        save_image(ii,mimic_1,'/content/another_save',True)\n","        # save_image(ii,g_1.predict(pred_album_1),'/content/another_another_save',True)\n","\n","    if ii%d_val_round==0:\n","      real_fb_1, real_fb_2, fake_fb_1, fake_fb_2=train_d.predict([data_g_1, data_g_2])\n","\n","      patch_sum=batch_size*patch_size*patch_size\n","\n","      real_fb_1=to_binary(real_fb_1)\n","      real_fb_2=to_binary(real_fb_2)\n","\n","      fake_fb_1=to_binary(fake_fb_1)\n","      fake_fb_2=to_binary(fake_fb_2)\n","\n","      real_accuracy_1=np.sum(real_fb_1)/patch_sum\n","      real_accuracy_2=np.sum(real_fb_2)/patch_sum\n","\n","      fake_accuracy_1=1-np.sum(fake_fb_1)/patch_sum\n","      fake_accuracy_2=1-np.sum(fake_fb_2)/patch_sum\n","\n","      d_accuracy=(real_accuracy_1+real_accuracy_2+fake_accuracy_1+fake_accuracy_2)/4\n","\n","      print('\\n')\n","      print('Discriminator accuracy: ', d_accuracy)\n","      print('\\n')\n","\n","\n","    if ii%save_net_round==0:\n","      g_2_dir='/content/save_model'\n","      g_2_name='g_2_{}__{}.h5'.format(ii,feedback_1[0])\n","      g_2_path=os.path.join(g_2_dir, g_2_name)\n","      g_2.save(g_2_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKletvUZ16Fm"},"outputs":[],"source":["image_shape=(256,256,1)\n","\n","opt=adam_v2.Adam(learning_rate=2e-4, beta_1=0.5)\n","\n","g_1=pp2_generator(image_shape, 1, 0.1,depth=64)\n","g_2=pp2_generator(image_shape, 1, 0.1,depth=64)\n","d_1=rg_patch_d(image_shape,adam_v2.Adam(learning_rate=2e-5, beta_1=0.5),lk_alpha=0.05, k_size=(5,5), init_k=32)\n","d_2=rg_patch_d(image_shape,adam_v2.Adam(learning_rate=2e-5, beta_1=0.5),lk_alpha=0.05, k_size=(5,5), init_k=32)\n","\n","load_path_1_HED=r'/content/data/Painting_HED'\n","load_path_1_Sobel=r'/content/data/Painting_Sobel'\n","load_path_2_HED=r'/content/data/Photo_HED'\n","load_path_2_Sobel=r'/content/data/Photo_Sobel'\n","\n","save_path_1=r''\n","save_path_2=r''\n","\n","Train_CycleGAN(g_1, g_2, d_1, d_2, load_path_1_HED, load_path_1_Sobel, load_path_2_HED, load_path_2_Sobel, save_path_1, save_path_2, image_shape, gd_ratio=4, pred_index_1=[37,46,84,115,132,172,181,183,211,217,262,265,282,337], pred_index_2=[11,37,46,84,115,132,172,181,183,211,217,262,265,282,337])"]},{"cell_type":"markdown","source":["# In Development: from image to ink painting pipeline"],"metadata":{"id":"tdKHxrAK4BvI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uMeQ6ouwMbbb"},"outputs":[],"source":["def to_ink(input):\n","  scaled_input = r\"/content/sample_data/scaled_input.png\"\n","  ratio = 0.4\n","  maxsize = (256, 256)\n","\n","  input_img=Image.open(input)\n","  input_img = crop_center_square(np.array(input_img))\n","  input_img=Image.fromarray(input_img.astype('uint8'))\n","  input_img = input_img.resize(maxsize, Image.ANTIALIAS)\n","  input_img.save(scaled_input)\n","\n","  cv_sobel(scaled_input, r\"/content/sample_data/sobel.png\")\n","  hed(scaled_input, r\"/content/sample_data/hed.png\")\n","\n","  HED_img_path=r\"/content/sample_data/hed.png\"\n","  HED_img=Image.open(HED_img_path)\n","\n","  Sobel_img_path=r\"/content/sample_data/sobel.png\"\n","  Sobel_img=Image.open(Sobel_img_path)\n","\n","  Sobel_img = np.array(Sobel_img)\n","  HED_img = np.array(HED_img)\n","\n","  img=ratio*Sobel_img+(1-ratio)*HED_img\n","  img=np.expand_dims(img,-1)\n","  img=np.expand_dims(img,0)\n","\n","  img=image_encode(img)\n","\n","  img=g_2.predict(img)\n","  output=g_p.predict(img)\n","  output = image_decode(output)\n","  output = np.squeeze(output)\n","\n","  output=Image.fromarray(output.astype('uint8'))\n","  # output.save(r'/content/sample_data'+'/output.png')\n","  # display(output)\n","\n","  return output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1129,"status":"ok","timestamp":1652456414019,"user":{"displayName":"Kelvin Li","userId":"13315570501262465020"},"user_tz":-60},"id":"FuKJZStn7UvH","outputId":"ed2aee54-f6da-488f-c8f0-bd2745577d31"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'pytorch-hed' already exists and is not an empty directory.\n","/content/pytorch-hed\n","comparison  images  LICENSE  README.md\trequirements.txt  run.py\n","/content\n","bash: download.bash: No such file or directory\n"]}],"source":["!git clone https://github.com/sniklaus/pytorch-hed.git\n","%cd pytorch-hed\n","!ls\n","%cd ..\n","!bash download.bash"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFAOjtZgw-Rj"},"outputs":[],"source":["import numpy as np\n","import cv2\n","import os\n","\n","def cv_sobel(in_path, out_path):\n","  image = cv2.imread(in_path)\n","  image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","\n","  sobelX = cv2.Sobel(image,cv2.CV_64F,1,0)\n","  sobelY = cv2.Sobel(image,cv2.CV_64F,0,1)\n","\n","  sobelX = np.uint8(np.absolute(sobelX))\n","  sobelY = np.uint8(np.absolute(sobelY))\n","\n","  sobelCombined = cv2.bitwise_or(sobelX,sobelY)#\n","\n","  cv2.imwrite(out_path, sobelCombined)\n","\n","def hed(in_path, out_path):\n","  os.system(\"python /content/pytorch-hed/run.py --model bsds500 --in \\'%s\\' --out \\'%s\\'\" %(in_path, out_path))\n","\n","def crop_center_square(a):\n","  i = a.shape[0]\n","  j = a.shape[1]\n","\n","  if i >= j:\n","    output = a[(i - j)//2 : (i - j)//2 + j]\n","  else:\n","    output = a[:, (j - i) // 2: (j - i) // 2 + i]\n","\n","  return output"]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Simple_Edge_CycleGAN.ipynb","provenance":[],"mount_file_id":"1l7rHpehHLMY0buao8rTRSP4Ekg9Dju2c","authorship_tag":"ABX9TyPtAr/HhjcgCjn0JFCqoA+L"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}